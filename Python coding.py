#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import seaborn as sns


# In[2]:


df=pd.read_csv("phishing_legitimate_full.csv")
#Tan, Choon Lin (2018), “Phishing Dataset for Machine Learning: Feature Evaluation”, Mendeley Data, V1, doi: 10.17632/h3cgnj8hft.1


# In[3]:


df # The dataset contain 10,000 rows and 50 columns


# In[4]:


df.head()


# In[5]:


# Name of columns showing the features in dataset
list(df.columns)


# In[6]:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('phishing_legitimate_full.csv')

# Count the number of samples in each class (CLASS_LABEL) using value_counts()
class_counts = df['CLASS_LABEL'].value_counts()

# Plot the bar chart
plt.figure(figsize=(6, 4))
plt.bar(class_counts.index, class_counts.values)
plt.xlabel('Class')
plt.ylabel('Number of Samples')
plt.title('Dataset Class Distribution')
plt.xticks(class_counts.index, ['Phishing', 'Legitimate'])
plt.show()


# In[7]:


sns.histplot(df.CLASS_LABEL)
plt.title('Phishing Website')
plt.show()


# In[8]:


df.shape


# In[9]:


df.describe()#dataset analystic giving statistical measure


# In[10]:


df['CLASS_LABEL'].value_counts()#shows how much phished websites(1)and lgitimate website(0)


# In[11]:


df.groupby('CLASS_LABEL').mean()# shows the mean value in accordance with labels


# In[12]:


x = df.iloc[:,0:-1].values
y = df.iloc[:,-1].values
# Determining class features and input features


# In[13]:


x


# In[14]:


y


# In[15]:


# Splitting the dataset into training set and Test Set
from sklearn.model_selection import train_test_split
x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=0)


# In[16]:


sns.countplot(x = y_train)


# In[17]:


# Training the KNN Model


# In[18]:


import pandas as pd
df=pd.read_csv("phishing_legitimate_full.csv")
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
x = df.iloc[:,0:-1].values
y = df.iloc[:,-1].values
x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=0)
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[19]:


# Adding K-NN to the Training Set
from sklearn.neighbors import KNeighborsClassifier
classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)
classifier.fit(x_train_s,y_train)


# In[20]:


# Evaluating the Model
# Prediting the Test set result
y_pred=classifier.predict(x_test)
print(y_pred)


# In[21]:


print(y_test)


# In[22]:


from sklearn import metrics
acc=metrics.accuracy_score(y_test,y_pred)
print('accuracy:%2f\n\n'%(acc))
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred)
print('Classification Report:\n')
print(result)


# In[23]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[24]:


# Training the Decision Tree Model


# In[25]:


import pandas as pd
df=pd.read_csv("phishing_legitimate_full.csv")
from sklearn.model_selection import train_test_split
x = df.iloc[:,0:-1].values
y = df.iloc[:,-1].values
x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=0)
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[26]:


# Adding Decision Tree to the Training Set
from sklearn.tree import DecisionTreeClassifier
classifier=DecisionTreeClassifier(criterion='entropy',random_state=0)
classifier.fit(x_train_s,y_train)


# In[27]:


# Evaluating the Model
# Prediting the Test set result
y_pred=classifier.predict(x_test)
print(y_pred)


# In[28]:


print(y_test)


# In[29]:


from sklearn import metrics
acc=metrics.accuracy_score(y_test,y_pred)
print('accuracy:%2f\n\n'%(acc))
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred,zero_division=1)
print('Classification Report:\n')
print(result)





# In[30]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[31]:


# Training the Random Forest Model


# In[32]:


from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[33]:


# Adding Random Forest to the Training Set
from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(x_train_s,y_train)


# In[34]:


# Evaluating the Model
# Prediting the Test set result
y_pred=classifier.predict(x_test)
print(y_pred)


# In[35]:


print(y_test)


# In[36]:


from sklearn import metrics
acc=metrics.accuracy_score(y_test,y_pred)
print('accuracy:%2f\n\n'%(acc))
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred,zero_division=1)
print('Classification Report:\n')
print(result)


# In[37]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[38]:


# Training the Support Vector Machine Model


# In[39]:


from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[40]:


# Adding SVM to the Training Set
from sklearn.svm import SVC
svm_classifier=SVC(kernel='linear', C=1.0, random_state=42)
svm_classifier.fit(x_train_s,y_train)


# In[41]:


# Evaluating the Model
# Prediting the Test set result
y_pred = svm_classifier.predict(x_test)



# In[42]:


print(y_test)


# In[43]:


from sklearn.metrics import accuracy_score
y_pred = svm_classifier.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


# In[44]:


from sklearn import metrics
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred,zero_division=1)
print('Classification Report:\n')
print(result)


# In[45]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[46]:


# Training the Logistic Regression Model


# In[47]:


from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[48]:


# Adding Logistic Regression to the Training Set
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
# Create a Logistic Regression classifier
logreg_classifier = LogisticRegression(random_state=42,solver="liblinear")
# Fit the classifier to the training data
logreg_classifier.fit(x_train, y_train)


# In[49]:


y_pred = logreg_classifier.predict(x_test)

# Evaluate the model's performance using accuracy as an metric
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


# In[50]:


from sklearn import metrics
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred)
print('Classification Report:\n')
print(result)


# In[51]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[52]:


# Training XG Boost Model


# In[53]:


import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
df=pd.read_csv("phishing_legitimate_full.csv")
x = df.iloc[:, 0:-1].values
y = df.iloc[:, -1].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[54]:


# Adding XG Boost to the Training Set
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
xgB_classifier=XGBClassifier()
# Fit the classifier to the training data
xgB_classifier.fit(x_train, y_train)


# In[55]:


y_pred = xgB_classifier.predict(x_test)

# Evaluate the model's performance using accuracy as an metric
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
from sklearn import metrics
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred)
print('Classification Report:\n')
print(result)


# In[56]:


import seaborn as sns
import matplotlib.pyplot as plt
ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[57]:


# Training Navie Bayes Model


# In[58]:


from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_s=sc.fit_transform(x_train)
x_test_s=sc.transform(x_test)


# In[59]:


# Adding Navie Bayes For Training Set
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
x_train[x_train < 0] = 0
# Create a Naive Bayes classifier (Multinomial Naive Bayes)
nb_classifier = MultinomialNB()
# Fit the classifier to the training data
nb_classifier.fit(x_train, y_train)


# In[60]:


y_pred = nb_classifier.predict(x_test)

# Evaluate the model's performance using accuracy as an  metric
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


# In[61]:


from sklearn import metrics
cm=metrics.confusion_matrix(y_test,y_pred)
print('Confusion Matrix:')
print(cm,'\n\n')
print('---------------------------------------------------------')
result=metrics.classification_report(y_test,y_pred)
print('Classification Report:\n')
print(result)


# In[62]:


ax=sns.heatmap(cm,cmap='flare',annot=True,fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()


# In[63]:


import matplotlib.pyplot as plt

def graph():
    data = [logreg, dt, rf,xgb, sv, nb, kn]
    alg = ["LR", "DT", "RF","XGB", "SVM", "NB", "KNN"]
    plt.figure(figsize=(10, 5))
    b = plt.bar(alg, data, color=("r", "g", "b","pink", "y", "m", "black"))
    plt.title("Accuracy comparison of Algorithms", fontsize=15)
    plt.legend(b, data, fontsize=9)
    plt.savefig('overallaccuracy.png')
    plt.show()

logreg = 0.9935
dt = 0.506
rf = 0.506
xgb= 0.9995
sv = 0.506
nb = 0.825
kn = 0.510

graph()


# In[ ]:




